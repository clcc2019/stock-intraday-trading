#!/usr/bin/env python3
"""
æ•°æ®æºé€‚é…å±‚ â€” å¤šæ•°æ®æºè‡ªåŠ¨åˆ‡æ¢ï¼Œæé«˜å¯ç”¨æ€§
é¿å…å•ä¸€æ•°æ®æºé™æµå¯¼è‡´åŠŸèƒ½ä¸å¯ç”¨

æ•°æ®æºä¼˜å…ˆçº§ï¼š
1. baostockï¼ˆä¸»ï¼‰ï¼šç¨³å®šã€å…è´¹ã€ä¸é™æµï¼Œæ¥è‡ªè¯åˆ¸äº¤æ˜“æ‰€ï¼ˆå†å²Kçº¿ï¼‰
2. akshareï¼ˆå¤‡ï¼‰ï¼šå†å²Kçº¿å¤‡ç”¨
3. adataï¼ˆè¡¥å……ï¼‰ï¼šå®æ—¶è¡Œæƒ…ã€èµ„é‡‘æµå‘ã€åˆ†æ—¶è¡Œæƒ…ã€5æ¡£ç›˜å£

ä¼˜åŒ–ç­–ç•¥ï¼š
- è‡ªåŠ¨é‡è¯•å’Œé™çº§åˆ‡æ¢
- ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤æŸ¥è¯¢ï¼ˆ5åˆ†é’ŸTTLï¼‰
- æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–
"""

import baostock as bs
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import time
import hashlib
import os

warnings.filterwarnings('ignore')

# ç£ç›˜ç¼“å­˜ç›®å½•
_CACHE_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), '.cache')
os.makedirs(_CACHE_DIR, exist_ok=True)

# å»¶è¿Ÿå¯¼å…¥ adataï¼ˆå¯é€‰ä¾èµ–ï¼‰
_adata = None
_adata_available = None  # None=æœªæ£€æµ‹, True=å¯ç”¨, False=ä¸å¯ç”¨


def _get_adata():
    """å»¶è¿Ÿå¯¼å…¥ adata"""
    global _adata, _adata_available
    if _adata_available is False:
        return None
    if _adata is None:
        try:
            import adata
            _adata = adata
            _adata_available = True
        except ImportError:
            _adata_available = False
            return None
    return _adata


class DataSource:
    """ç»Ÿä¸€æ•°æ®æºæ¥å£ â€” å¤šæ•°æ®æºè‡ªåŠ¨åˆ‡æ¢"""
    
    _logged_in = False
    _cache = {}  # ç®€å•å†…å­˜ç¼“å­˜
    _cache_ttl = 300  # ç¼“å­˜5åˆ†é’Ÿ
    _cache_write_count = 0  # å†™å…¥è®¡æ•°ï¼Œç”¨äºè§¦å‘æ¸…ç†
    _akshare_available = None  # None=æœªæ£€æµ‹, True=å¯ç”¨, False=ä¸å¯ç”¨
    
    @classmethod
    def login(cls):
        """ç™»å½• baostock"""
        if not cls._logged_in:
            lg = bs.login()
            if lg.error_code == '0':
                cls._logged_in = True
            else:
                raise Exception(f"baostock ç™»å½•å¤±è´¥: {lg.error_msg}")
    
    @classmethod
    def logout(cls):
        """ç™»å‡º baostock"""
        if cls._logged_in:
            bs.logout()
            cls._logged_in = False
    
    @classmethod
    def _get_cache_key(cls, *args, **kwargs):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = str(args) + str(sorted(kwargs.items()))
        return hashlib.md5(key_str.encode()).hexdigest()
    
    @classmethod
    def _get_cache(cls, key):
        """è·å–ç¼“å­˜"""
        if key in cls._cache:
            data, timestamp = cls._cache[key]
            if time.time() - timestamp < cls._cache_ttl:
                return data
            else:
                del cls._cache[key]
        return None
    
    @classmethod
    def _set_cache(cls, key, data):
        """è®¾ç½®ç¼“å­˜ï¼Œæ¯100æ¬¡å†™å…¥æ¸…ç†ä¸€æ¬¡è¿‡æœŸæ¡ç›®"""
        cls._cache[key] = (data, time.time())
        cls._cache_write_count += 1
        if cls._cache_write_count >= 100:
            cls._cleanup_cache()
            cls._cache_write_count = 0

    @classmethod
    def _cleanup_cache(cls):
        """æ¸…ç†æ‰€æœ‰è¿‡æœŸç¼“å­˜æ¡ç›®"""
        now = time.time()
        expired_keys = [
            k for k, (_, ts) in cls._cache.items()
            if now - ts >= cls._cache_ttl
        ]
        for k in expired_keys:
            del cls._cache[k]

    @classmethod
    def clear_disk_cache(cls, stock_code=None):
        """æ¸…ç†ç£ç›˜ç¼“å­˜
        
        å‚æ•°:
            stock_code: æŒ‡å®šè‚¡ç¥¨ä»£ç ï¼Œä¸º None æ¸…ç†å…¨éƒ¨
        """
        if stock_code:
            import glob
            pattern = os.path.join(_CACHE_DIR, f'{stock_code}_*.csv')
            for f in glob.glob(pattern):
                os.remove(f)
        else:
            import shutil
            if os.path.exists(_CACHE_DIR):
                shutil.rmtree(_CACHE_DIR)
                os.makedirs(_CACHE_DIR, exist_ok=True)
    
    @classmethod
    def _convert_code(cls, stock_code):
        """è½¬æ¢è‚¡ç¥¨ä»£ç ä¸º baostock æ ¼å¼"""
        if stock_code.startswith('6'):
            return f'sh.{stock_code}'
        elif stock_code.startswith(('0', '3')):
            return f'sz.{stock_code}'
        else:
            return f'sh.{stock_code}'
    
    @classmethod
    def get_stock_hist_minute(cls, stock_code, start_date=None, end_date=None, adjust='qfq', period='5'):
        """
        è·å–è‚¡ç¥¨åˆ†é’ŸKçº¿æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        å‚æ•°:
            stock_code: 6ä½è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '600519'
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD' æˆ– datetime
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD' æˆ– datetime
            adjust: å¤æƒç±»å‹ï¼Œ'qfq'=å‰å¤æƒ, 'hfq'=åå¤æƒ, ''=ä¸å¤æƒ
            period: å‘¨æœŸï¼Œ'5'=5åˆ†é’Ÿ, '15'=15åˆ†é’Ÿ, '30'=30åˆ†é’Ÿ, '60'=60åˆ†é’Ÿ
        
        è¿”å›:
            DataFrameï¼Œåˆ—åä¸ akshare å…¼å®¹ï¼šæ—¶é—´ã€å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ã€æˆäº¤é‡
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = cls._get_cache_key('minute', stock_code, start_date, end_date, adjust, period)
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()
        
        cls.login()
        
        # å¤„ç†æ—¥æœŸæ ¼å¼
        if isinstance(start_date, datetime):
            start_date = start_date.strftime('%Y-%m-%d')
        elif start_date and len(start_date) == 8:
            start_date = f'{start_date[:4]}-{start_date[4:6]}-{start_date[6:]}'
        
        if isinstance(end_date, datetime):
            end_date = end_date.strftime('%Y-%m-%d')
        elif end_date and len(end_date) == 8:
            end_date = f'{end_date[:4]}-{end_date[4:6]}-{end_date[6:]}'
        
        # é»˜è®¤æ—¥æœŸï¼ˆä»Šå¤©ï¼‰
        if not end_date:
            end_date = datetime.now().strftime('%Y-%m-%d')
        if not start_date:
            start_date = end_date
        
        # è½¬æ¢ä»£ç 
        bs_code = cls._convert_code(stock_code)
        
        # å¤æƒç±»å‹æ˜ å°„
        adjust_map = {'qfq': '2', 'hfq': '1', '': '3'}
        adjustflag = adjust_map.get(adjust, '2')
        
        # æŸ¥è¯¢æ•°æ®
        rs = bs.query_history_k_data_plus(
            bs_code,
            'date,time,code,open,high,low,close,volume',
            start_date=start_date,
            end_date=end_date,
            frequency=period,
            adjustflag=adjustflag
        )
        
        if rs.error_code != '0':
            raise Exception(f"baostock æŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
        
        # è½¬æ¢ä¸º DataFrame
        data_list = []
        while rs.next():
            data_list.append(rs.get_row_data())
        
        if not data_list:
            return pd.DataFrame()
        
        df = pd.DataFrame(data_list, columns=rs.fields)
        
        # æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆbaostock è¿”å›å¦‚ '20260206093500000'ï¼‰
        df['æ—¶é—´'] = pd.to_datetime(df['time'], format='%Y%m%d%H%M%S%f').dt.strftime('%Y-%m-%d %H:%M:%S')
        
        # åˆ—åæ˜ å°„ï¼ˆå…¼å®¹ akshareï¼‰
        df = df.rename(columns={
            'open': 'å¼€ç›˜',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½',
            'close': 'æ”¶ç›˜',
            'volume': 'æˆäº¤é‡',
        })
        
        # æ•°æ®ç±»å‹è½¬æ¢
        for col in ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df['æˆäº¤é‡'] = pd.to_numeric(df['æˆäº¤é‡'], errors='coerce').fillna(0).astype(np.int64)
        
        result = df[['æ—¶é—´', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']]
        cls._set_cache(cache_key, result)
        return result
    
    # ============================================================
    # ç£ç›˜ç¼“å­˜ï¼šæ™ºèƒ½å¢é‡æ›´æ–°å†å²Kçº¿
    # ============================================================

    @classmethod
    def _disk_cache_path(cls, stock_code, adjust, period):
        """ç”Ÿæˆç£ç›˜ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return os.path.join(_CACHE_DIR, f'{stock_code}_{period}_{adjust}.csv')

    _disk_update_times = {}  # {cache_path: last_update_timestamp}
    _DISK_UPDATE_COOLDOWN = 900  # 15åˆ†é’Ÿå¢é‡å†·å´æœŸ

    @classmethod
    def _load_disk_cache(cls, stock_code, adjust, period):
        """ä»ç£ç›˜è¯»å–ç¼“å­˜"""
        path = cls._disk_cache_path(stock_code, adjust, period)
        if not os.path.exists(path):
            return None
        try:
            df = pd.read_csv(path, dtype={'æ—¥æœŸ': str})
            if df.empty or 'æ—¥æœŸ' not in df.columns:
                return None
            # ç±»å‹è½¬æ¢
            for col in ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æ¢æ‰‹ç‡', 'æ¶¨è·Œå¹…']:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            if 'æˆäº¤é‡' in df.columns:
                df['æˆäº¤é‡'] = pd.to_numeric(df['æˆäº¤é‡'], errors='coerce').fillna(0).astype(np.int64)
            if 'æˆäº¤é¢' in df.columns:
                df['æˆäº¤é¢'] = pd.to_numeric(df['æˆäº¤é¢'], errors='coerce').fillna(0).astype(np.float64)
            return df
        except Exception:
            return None

    @classmethod
    def _should_try_increment(cls, stock_code, adjust, period):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å°è¯•å¢é‡æ›´æ–°ï¼ˆå†·å´æœŸå†…è·³è¿‡è”ç½‘ï¼‰"""
        path = cls._disk_cache_path(stock_code, adjust, period)
        last_update = cls._disk_update_times.get(path)
        if last_update is None:
            # é¦–æ¬¡ï¼šç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´åˆ¤æ–­
            if os.path.exists(path):
                mtime = os.path.getmtime(path)
                if time.time() - mtime < cls._DISK_UPDATE_COOLDOWN:
                    return False
        else:
            if time.time() - last_update < cls._DISK_UPDATE_COOLDOWN:
                return False
        return True

    @classmethod
    def _mark_disk_updated(cls, stock_code, adjust, period):
        """æ ‡è®°ç£ç›˜ç¼“å­˜å·²æ›´æ–°"""
        path = cls._disk_cache_path(stock_code, adjust, period)
        cls._disk_update_times[path] = time.time()

    @classmethod
    def _save_disk_cache(cls, df, stock_code, adjust, period):
        """ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜"""
        if df is None or df.empty:
            return
        path = cls._disk_cache_path(stock_code, adjust, period)
        try:
            df.to_csv(path, index=False)
        except Exception:
            pass

    @classmethod
    def get_stock_hist(cls, stock_code, start_date=None, end_date=None, adjust='qfq', period='daily'):
        """
        è·å–è‚¡ç¥¨å†å²Kçº¿æ•°æ®ï¼ˆç£ç›˜ç¼“å­˜ + æ™ºèƒ½å¢é‡æ›´æ–°ï¼‰
        
        æ€§èƒ½ä¼˜åŒ–ï¼š
        1. é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜ï¼ˆ5åˆ†é’ŸTTLï¼‰
        2. å†æ£€æŸ¥ç£ç›˜ç¼“å­˜ï¼Œå¦‚æœ‰åˆ™åªæŸ¥è¯¢ç¼ºå¤±çš„å¢é‡æ•°æ®
        3. æ— ç¼“å­˜æ‰å…¨é‡æŸ¥è¯¢
        
        å‚æ•°:
            stock_code: 6ä½è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '600519'
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD' æˆ– datetime
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ 'YYYYMMDD' æˆ– datetime
            adjust: å¤æƒç±»å‹ï¼Œ'qfq'=å‰å¤æƒ, 'hfq'=åå¤æƒ, ''=ä¸å¤æƒ
            period: å‘¨æœŸï¼Œ'daily'=æ—¥çº¿, 'weekly'=å‘¨çº¿, 'monthly'=æœˆçº¿
        
        è¿”å›:
            DataFrameï¼Œåˆ—åä¸ akshare å…¼å®¹ï¼šæ—¥æœŸã€å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜ã€æˆäº¤é‡ã€æˆäº¤é¢ã€æ¢æ‰‹ç‡
        """
        # 1. æ£€æŸ¥å†…å­˜ç¼“å­˜
        cache_key = cls._get_cache_key('hist', stock_code, start_date, end_date, adjust, period)
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()
        
        # æ ‡å‡†åŒ–æ—¥æœŸ
        if isinstance(end_date, datetime):
            end_str = end_date.strftime('%Y-%m-%d')
        elif end_date and len(str(end_date)) == 8:
            end_str = f'{str(end_date)[:4]}-{str(end_date)[4:6]}-{str(end_date)[6:]}'
        elif end_date:
            end_str = str(end_date)
        else:
            end_str = datetime.now().strftime('%Y-%m-%d')

        if isinstance(start_date, datetime):
            start_str = start_date.strftime('%Y-%m-%d')
        elif start_date and len(str(start_date)) == 8:
            start_str = f'{str(start_date)[:4]}-{str(start_date)[4:6]}-{str(start_date)[6:]}'
        elif start_date:
            start_str = str(start_date)
        else:
            start_str = (datetime.now() - timedelta(days=400)).strftime('%Y-%m-%d')

        # 2. ç£ç›˜ç¼“å­˜ + æ™ºèƒ½å¢é‡æ›´æ–°ï¼ˆä»…æ—¥çº¿/å‘¨çº¿ï¼‰
        if period in ('daily', 'weekly'):
            disk_df = cls._load_disk_cache(stock_code, adjust, period)
            if disk_df is not None and len(disk_df) > 0:
                last_cached_date = str(disk_df['æ—¥æœŸ'].iloc[-1])
                # å¦‚æœç¼“å­˜å·²ç»è¦†ç›–åˆ°ä»Šå¤©æˆ–æ˜¨å¤©ï¼Œç›´æ¥ç”¨ç¼“å­˜
                today_str = datetime.now().strftime('%Y-%m-%d')
                yesterday_str = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
                if last_cached_date >= yesterday_str:
                    # ç¼“å­˜è¶³å¤Ÿæ–°ï¼Œæ£€æŸ¥å†·å´æœŸå†å†³å®šæ˜¯å¦å¢é‡
                    if cls._should_try_increment(stock_code, adjust, period):
                        incr_start = (datetime.strptime(last_cached_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
                        if incr_start <= today_str:
                            try:
                                incr_df = cls._fetch_from_source(stock_code, incr_start, end_str, adjust, period)
                                if incr_df is not None and not incr_df.empty:
                                    disk_df = pd.concat([disk_df, incr_df], ignore_index=True)
                                    disk_df = disk_df.drop_duplicates(subset=['æ—¥æœŸ'], keep='last').sort_values('æ—¥æœŸ').reset_index(drop=True)
                                    cls._save_disk_cache(disk_df, stock_code, adjust, period)
                            except Exception:
                                pass  # å¢é‡å¤±è´¥ç”¨ç°æœ‰ç¼“å­˜
                        cls._mark_disk_updated(stock_code, adjust, period)
                    # æŒ‰è¯·æ±‚æ—¥æœŸèŒƒå›´è¿‡æ»¤
                    result = disk_df[(disk_df['æ—¥æœŸ'] >= start_str) & (disk_df['æ—¥æœŸ'] <= end_str)].reset_index(drop=True)
                    if not result.empty:
                        cls._set_cache(cache_key, result)
                        return result.copy()
                elif last_cached_date >= start_str:
                    # ç¼“å­˜éƒ¨åˆ†è¦†ç›–ï¼Œè¿½åŠ åé¢ç¼ºå¤±çš„éƒ¨åˆ†
                    incr_start = (datetime.strptime(last_cached_date, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d')
                    try:
                        incr_df = cls._fetch_from_source(stock_code, incr_start, end_str, adjust, period)
                        if incr_df is not None and not incr_df.empty:
                            disk_df = pd.concat([disk_df, incr_df], ignore_index=True)
                            disk_df = disk_df.drop_duplicates(subset=['æ—¥æœŸ'], keep='last').sort_values('æ—¥æœŸ').reset_index(drop=True)
                            cls._save_disk_cache(disk_df, stock_code, adjust, period)
                            cls._mark_disk_updated(stock_code, adjust, period)
                            result = disk_df[(disk_df['æ—¥æœŸ'] >= start_str) & (disk_df['æ—¥æœŸ'] <= end_str)].reset_index(drop=True)
                            if not result.empty:
                                cls._set_cache(cache_key, result)
                                return result.copy()
                    except Exception:
                        pass

        # 3. å…¨é‡è·å–ï¼ˆæ— ç¼“å­˜æˆ–ç¼“å­˜å¤±æ•ˆï¼‰
        df = cls._fetch_from_source(stock_code, start_str, end_str, adjust, period)
        if df is not None and not df.empty:
            cls._set_cache(cache_key, df)
            if period in ('daily', 'weekly'):
                # åˆå¹¶ä¿å­˜ï¼ˆä¿ç•™æ›´å¤šå†å²æ•°æ®ï¼‰
                disk_df = cls._load_disk_cache(stock_code, adjust, period)
                if disk_df is not None and not disk_df.empty:
                    merged = pd.concat([disk_df, df], ignore_index=True)
                    merged = merged.drop_duplicates(subset=['æ—¥æœŸ'], keep='last').sort_values('æ—¥æœŸ').reset_index(drop=True)
                    cls._save_disk_cache(merged, stock_code, adjust, period)
                else:
                    cls._save_disk_cache(df, stock_code, adjust, period)
            return df
        
        return pd.DataFrame()

    @classmethod
    def _fetch_from_source(cls, stock_code, start_date, end_date, adjust, period):
        """ä»æ•°æ®æºè·å–æ•°æ®ï¼ˆbaostock ä¸» â†’ akshare å¤‡ï¼‰"""
        # å°è¯• baostockï¼ˆä¸»æ•°æ®æºï¼‰
        try:
            df = cls._get_stock_hist_baostock(stock_code, start_date, end_date, adjust, period)
            if df is not None and not df.empty:
                return df
        except Exception:
            pass
        
        # é™çº§åˆ° akshareï¼ˆå¤‡ç”¨æ•°æ®æºï¼‰
        if cls._akshare_available is not False:
            try:
                import akshare as ak
                df = cls._get_stock_hist_akshare(ak, stock_code, start_date, end_date, adjust, period)
                if df is not None and not df.empty:
                    cls._akshare_available = True
                    return df
            except Exception:
                cls._akshare_available = False
        
        return pd.DataFrame()
    
    @classmethod
    def _get_stock_hist_baostock(cls, stock_code, start_date, end_date, adjust, period):
        """ä» baostock è·å–å†å²æ•°æ®"""
        cls.login()
        
        # å¤„ç†æ—¥æœŸæ ¼å¼
        if isinstance(start_date, datetime):
            start_date = start_date.strftime('%Y-%m-%d')
        elif start_date and len(start_date) == 8:
            start_date = f'{start_date[:4]}-{start_date[4:6]}-{start_date[6:]}'
        
        if isinstance(end_date, datetime):
            end_date = end_date.strftime('%Y-%m-%d')
        elif end_date and len(end_date) == 8:
            end_date = f'{end_date[:4]}-{end_date[4:6]}-{end_date[6:]}'
        
        # é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = datetime.now().strftime('%Y-%m-%d')
        if not start_date:
            start_date = (datetime.now() - timedelta(days=400)).strftime('%Y-%m-%d')
        
        # è½¬æ¢ä»£ç 
        bs_code = cls._convert_code(stock_code)
        
        # å¤æƒç±»å‹æ˜ å°„
        adjust_map = {'qfq': '2', 'hfq': '1', '': '3'}
        adjustflag = adjust_map.get(adjust, '2')
        
        # å‘¨æœŸæ˜ å°„
        freq_map = {'daily': 'd', 'weekly': 'w', 'monthly': 'm'}
        frequency = freq_map.get(period, 'd')
        
        # æŸ¥è¯¢æ•°æ®
        rs = bs.query_history_k_data_plus(
            bs_code,
            'date,code,open,high,low,close,volume,amount,turn,pctChg',
            start_date=start_date,
            end_date=end_date,
            frequency=frequency,
            adjustflag=adjustflag
        )
        
        if rs.error_code != '0':
            raise Exception(f"baostock æŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
        
        # è½¬æ¢ä¸º DataFrame
        data_list = []
        while rs.next():
            data_list.append(rs.get_row_data())
        
        if not data_list:
            return pd.DataFrame()
        
        df = pd.DataFrame(data_list, columns=rs.fields)
        
        # åˆ—åæ˜ å°„ï¼ˆå…¼å®¹ akshareï¼‰
        df = df.rename(columns={
            'date': 'æ—¥æœŸ',
            'open': 'å¼€ç›˜',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½',
            'close': 'æ”¶ç›˜',
            'volume': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'turn': 'æ¢æ‰‹ç‡',
            'pctChg': 'æ¶¨è·Œå¹…',
        })
        
        # æ•°æ®ç±»å‹è½¬æ¢
        for col in ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æ¢æ‰‹ç‡', 'æ¶¨è·Œå¹…']:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # æˆäº¤é‡å’Œæˆäº¤é¢ï¼ˆbaostock è¿”å›çš„æ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬æ¢ï¼‰
        df['æˆäº¤é‡'] = pd.to_numeric(df['æˆäº¤é‡'], errors='coerce').fillna(0).astype(np.int64)
        df['æˆäº¤é¢'] = pd.to_numeric(df['æˆäº¤é¢'], errors='coerce').fillna(0).astype(np.float64)
        
        return df
    
    @classmethod
    def _get_stock_hist_akshare(cls, ak, stock_code, start_date, end_date, adjust, period):
        """ä» akshare è·å–å†å²æ•°æ®ï¼ˆå¤‡ç”¨ï¼‰"""
        # å¤„ç†æ—¥æœŸæ ¼å¼
        if isinstance(start_date, datetime):
            start_date = start_date.strftime('%Y%m%d')
        elif start_date and '-' in str(start_date):
            start_date = str(start_date).replace('-', '')
        
        if isinstance(end_date, datetime):
            end_date = end_date.strftime('%Y%m%d')
        elif end_date and '-' in str(end_date):
            end_date = str(end_date).replace('-', '')
        
        # é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')
        if not start_date:
            start_date = (datetime.now() - timedelta(days=400)).strftime('%Y%m%d')
        
        # è°ƒç”¨ akshare
        df = ak.stock_zh_a_hist(
            symbol=stock_code,
            period=period,
            start_date=start_date,
            end_date=end_date,
            adjust=adjust
        )
        
        return df
    
    @classmethod
    def get_stock_list(cls):
        """
        è·å–å…¨éƒ¨Aè‚¡åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        è¿”å›:
            DataFrameï¼ŒåŒ…å« codeï¼ˆè‚¡ç¥¨ä»£ç ï¼‰ã€code_nameï¼ˆè‚¡ç¥¨åç§°ï¼‰
        """
        cache_key = cls._get_cache_key('stock_list')
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()
        
        cls.login()
        
        rs = bs.query_all_stock(day=datetime.now().strftime('%Y-%m-%d'))
        
        if rs.error_code != '0':
            raise Exception(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {rs.error_msg}")
        
        data_list = []
        while rs.next():
            data_list.append(rs.get_row_data())
        
        df = pd.DataFrame(data_list, columns=rs.fields)
        
        # è¿‡æ»¤Aè‚¡ï¼ˆsh/szå¼€å¤´ï¼‰
        df = df[df['code'].str.startswith(('sh.', 'sz.'))]
        
        # æå–6ä½ä»£ç 
        df['stock_code'] = df['code'].str.replace('sh.', '').str.replace('sz.', '')
        
        # è¿‡æ»¤STè‚¡ã€é€€å¸‚è‚¡ã€åŒ—äº¤æ‰€
        df = df[~df['code_name'].str.contains('ST|é€€å¸‚|\\*', na=False, regex=True)]
        df = df[~df['stock_code'].str.startswith(('8', '9', '4'))]
        
        result = df[['stock_code', 'code_name']].rename(columns={
            'stock_code': 'ä»£ç ',
            'code_name': 'åç§°'
        })
        
        cls._set_cache(cache_key, result)
        return result
    
    @classmethod
    def get_index_stocks(cls, index_code):
        """
        è·å–æŒ‡æ•°æˆåˆ†è‚¡ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        å‚æ•°:
            index_code: æŒ‡æ•°ä»£ç ï¼Œå¦‚ 'sh.000300'ï¼ˆæ²ªæ·±300ï¼‰
            æ”¯æŒ: sh.000300(æ²ªæ·±300), sh.000905(ä¸­è¯500), sh.000016(ä¸Šè¯50)
        
        è¿”å›:
            DataFrameï¼ŒåŒ…å« ä»£ç ï¼ˆè‚¡ç¥¨ä»£ç ï¼‰ã€åç§°ï¼ˆè‚¡ç¥¨åç§°ï¼‰
        """
        cache_key = cls._get_cache_key('index_stocks', index_code)
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()
        
        cls.login()
        
        # æ ¹æ®æŒ‡æ•°ä»£ç é€‰æ‹©æ­£ç¡®çš„ baostock API
        api_map = {
            'sh.000300': bs.query_hs300_stocks,
            'sh.000905': bs.query_zz500_stocks,
            'sh.000016': bs.query_sz50_stocks,
        }
        query_fn = api_map.get(index_code)
        if query_fn is None:
            raise Exception(f"ä¸æ”¯æŒçš„æŒ‡æ•°: {index_code}ï¼Œæ”¯æŒ: sh.000300(æ²ªæ·±300), sh.000905(ä¸­è¯500), sh.000016(ä¸Šè¯50)")
        
        date_str = datetime.now().strftime('%Y-%m-%d')
        rs = query_fn(date=date_str)
        
        if rs.error_code != '0':
            # å¦‚æœå¤±è´¥ï¼Œå°è¯•å‰ä¸€ä¸ªäº¤æ˜“æ—¥
            yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            rs = query_fn(date=yesterday)
        
        if rs.error_code != '0':
            raise Exception(f"è·å–æŒ‡æ•°æˆåˆ†è‚¡å¤±è´¥: {rs.error_msg}")
        
        data_list = []
        while rs.next():
            data_list.append(rs.get_row_data())
        
        df = pd.DataFrame(data_list, columns=rs.fields)
        
        # æå–6ä½ä»£ç 
        df['stock_code'] = df['code'].str.replace('sh.', '').str.replace('sz.', '')
        
        result = df[['stock_code', 'code_name']].rename(columns={
            'stock_code': 'ä»£ç ',
            'code_name': 'åç§°'
        })
        
        cls._set_cache(cache_key, result)
        return result
    
    @classmethod
    def batch_get_stock_hist(cls, stock_codes, start_date=None, end_date=None, adjust='qfq', period='daily'):
        """
        æ‰¹é‡è·å–è‚¡ç¥¨å†å²æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼Œå‡å°‘æŸ¥è¯¢æ¬¡æ•°ï¼‰
        
        å‚æ•°:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            å…¶ä»–å‚æ•°åŒ get_stock_hist
        
        è¿”å›:
            dict: {stock_code: DataFrame}
        """
        results = {}
        for code in stock_codes:
            try:
                df = cls.get_stock_hist(code, start_date, end_date, adjust, period)
                if df is not None and not df.empty:
                    results[code] = df
            except Exception:
                continue
        return results

    # ============================================================
    # adata è¡¥å……æ•°æ®æºï¼šå®æ—¶è¡Œæƒ… / èµ„é‡‘æµå‘ / åˆ†æ—¶ / 5æ¡£ç›˜å£
    # ============================================================

    @classmethod
    def get_realtime_quote(cls, stock_codes):
        """
        è·å–å®æ—¶è¡Œæƒ…ï¼ˆæ¥æºï¼šadataï¼Œæ–°æµª/è…¾è®¯ï¼‰
        
        å‚æ•°:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚ ['600519', '002594']
        
        è¿”å›:
            DataFrame: stock_code, short_name, price, change, change_pct, volume, amount
            å¤±è´¥è¿”å› None
        """
        cache_key = cls._get_cache_key('realtime', tuple(sorted(stock_codes)))
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()

        ad = _get_adata()
        if ad is None:
            return None
        try:
            df = ad.stock.market.list_market_current(code_list=stock_codes)
            if df is not None and not df.empty:
                # çŸ­ç¼“å­˜ï¼ˆ30ç§’ï¼‰
                cls._cache[cache_key] = (df, time.time())
                return df
        except Exception:
            pass
        return None

    @classmethod
    def get_capital_flow(cls, stock_code, days=30):
        """
        è·å–èµ„é‡‘æµå‘ï¼ˆæ¥æºï¼šadataï¼Œä¸œæ–¹è´¢å¯Œï¼‰
        
        å‚æ•°:
            stock_code: 6ä½è‚¡ç¥¨ä»£ç 
            days: è¿”å›æœ€è¿‘ N å¤©çš„æ•°æ®
        
        è¿”å›:
            DataFrame: stock_code, trade_date, main_net_inflow, sm_net_inflow,
                       mid_net_inflow, lg_net_inflow, max_net_inflow
            å¤±è´¥è¿”å› None
        """
        cache_key = cls._get_cache_key('capital_flow', stock_code)
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.tail(days).copy()

        ad = _get_adata()
        if ad is None:
            return None
        try:
            df = ad.stock.market.get_capital_flow(stock_code=stock_code)
            if df is not None and not df.empty:
                cls._set_cache(cache_key, df)
                return df.tail(days).copy()
        except Exception:
            pass
        return None

    @classmethod
    def get_intraday_minute(cls, stock_code):
        """
        è·å–ä»Šæ—¥åˆ†æ—¶è¡Œæƒ…ï¼ˆæ¥æºï¼šadataï¼‰
        
        å‚æ•°:
            stock_code: 6ä½è‚¡ç¥¨ä»£ç 
        
        è¿”å›:
            DataFrame: stock_code, trade_time, price, change, change_pct,
                       volume, avg_price, amount
            å¤±è´¥è¿”å› None
        """
        cache_key = cls._get_cache_key('intraday_min', stock_code, datetime.now().strftime('%Y%m%d'))
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()

        ad = _get_adata()
        if ad is None:
            return None
        try:
            df = ad.stock.market.get_market_min(stock_code=stock_code)
            if df is not None and not df.empty:
                # çŸ­ç¼“å­˜ï¼ˆ60ç§’ï¼‰
                cls._cache[cache_key] = (df, time.time())
                return df
        except Exception:
            pass
        return None

    @classmethod
    def get_market_five(cls, stock_code):
        """
        è·å–5æ¡£ç›˜å£è¡Œæƒ…ï¼ˆæ¥æºï¼šadataï¼‰
        
        å‚æ•°:
            stock_code: 6ä½è‚¡ç¥¨ä»£ç 
        
        è¿”å›:
            DataFrame: åŒ…å« s1-s5(å–ä»·), sv1-sv5(å–é‡), b1-b5(ä¹°ä»·), bv1-bv5(ä¹°é‡)
            å¤±è´¥è¿”å› None
        """
        ad = _get_adata()
        if ad is None:
            return None
        try:
            df = ad.stock.market.get_market_five(stock_code=stock_code)
            if df is not None and not df.empty:
                return df
        except Exception:
            pass
        return None

    @classmethod
    def get_stock_concepts(cls, stock_code):
        """
        è·å–è‚¡ç¥¨æ‰€å±æ¦‚å¿µæ¿å—ï¼ˆæ¥æºï¼šadataï¼Œä¸œæ–¹è´¢å¯Œï¼‰
        
        å‚æ•°:
            stock_code: 6ä½è‚¡ç¥¨ä»£ç 
        
        è¿”å›:
            DataFrame: stock_code, concept_code, name, source, reason
            å¤±è´¥è¿”å› None
        """
        cache_key = cls._get_cache_key('concepts', stock_code)
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()

        ad = _get_adata()
        if ad is None:
            return None
        try:
            df = ad.stock.info.get_concept_east(stock_code=stock_code)
            if df is not None and not df.empty:
                cls._set_cache(cache_key, df)
                return df
        except Exception:
            pass
        return None

    @classmethod
    def get_index_realtime(cls):
        """
        è·å–æŒ‡æ•°å®æ—¶è¡Œæƒ…ï¼ˆæ¥æºï¼šadataï¼‰
        
        è¿”å›:
            DataFrame: index_code, trade_time, open, high, low, price, volume, amount, change, change_pct
            å¤±è´¥è¿”å› None
        """
        cache_key = cls._get_cache_key('index_realtime')
        cached = cls._get_cache(cache_key)
        if cached is not None:
            return cached.copy()

        ad = _get_adata()
        if ad is None:
            return None
        try:
            df = ad.stock.market.get_market_index_current()
            if df is not None and not df.empty:
                cls._cache[cache_key] = (df, time.time())
                return df
        except Exception:
            pass
        return None


def main():
    """æµ‹è¯•æ•°æ®æº"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 data_source.py <è‚¡ç¥¨ä»£ç >")
        print("ç¤ºä¾‹: python3 data_source.py 600519")
        sys.exit(1)
    
    stock_code = sys.argv[1]
    
    print(f"ğŸ“Š æµ‹è¯•è·å– {stock_code} çš„æ•°æ®...")
    
    try:
        df = DataSource.get_stock_hist(stock_code)
        print(f"âœ… è·å–åˆ° {len(df)} æ¡æ•°æ®")
        print("\næœ€è¿‘3å¤©æ•°æ®:")
        print(df.tail(3))
        
        print(f"\nåˆ—å: {df.columns.tolist()}")
        
        # æµ‹è¯•ç¼“å­˜
        print("\næµ‹è¯•ç¼“å­˜...")
        import time
        start = time.time()
        df2 = DataSource.get_stock_hist(stock_code)
        print(f"âœ… ç¼“å­˜å‘½ä¸­ï¼Œè€—æ—¶: {(time.time() - start)*1000:.0f}ms")
        
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
    finally:
        DataSource.logout()


if __name__ == "__main__":
    main()
